{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:58:52.992728Z","iopub.status.busy":"2024-04-24T17:58:52.992371Z","iopub.status.idle":"2024-04-24T17:58:52.998730Z","shell.execute_reply":"2024-04-24T17:58:52.997813Z","shell.execute_reply.started":"2024-04-24T17:58:52.992702Z"},"trusted":true},"outputs":[],"source":["from nltk.tokenize import RegexpTokenizer\n","import pandas as pd\n","from torch.nn.utils.rnn import pad_sequence\n","from collections import Counter\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,confusion_matrix\n","import torch\n","import warnings\n","from torch.utils.data import Dataset\n","import random\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:52.261873Z","iopub.status.busy":"2024-04-24T17:50:52.261444Z","iopub.status.idle":"2024-04-24T17:50:52.266679Z","shell.execute_reply":"2024-04-24T17:50:52.265777Z","shell.execute_reply.started":"2024-04-24T17:50:52.261847Z"},"trusted":true},"outputs":[],"source":["UNK_CUTOFF=3\n","UNKNOWN_TOKEN='<unk>'\n","START_TOKEN='<sos>'\n","END_TOKEN='eos'\n","PAD_TOKEN='<pad>'\n","\n","EMBEDDING_DIM=300\n","BATCH_SIZE=128\n","NUM_LABELS=4\n","HIDDEN_SIZE=300\n","lrate=0.001\n","EPOCHS=15"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:52.268084Z","iopub.status.busy":"2024-04-24T17:50:52.267829Z","iopub.status.idle":"2024-04-24T17:50:55.957191Z","shell.execute_reply":"2024-04-24T17:50:55.956156Z","shell.execute_reply.started":"2024-04-24T17:50:52.268062Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv('../input/ass3-curr/train.csv')\n","train_labels=df['Class Index'].tolist()\n","df=df['Description']\n","warnings.filterwarnings(\"ignore\")\n","sentences=[]\n","for sent in df:\n","    tokenizer=RegexpTokenizer(r'\\w+')\n","    tokens=tokenizer.tokenize(sent)\n","    tokens=[token.lower() for token in tokens]\n","    sentences.append(tokens)\n","for sen in sentences:\n","    sen.insert(0,START_TOKEN)\n","    sen.append(END_TOKEN)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:55.960946Z","iopub.status.busy":"2024-04-24T17:50:55.960068Z","iopub.status.idle":"2024-04-24T17:50:59.014402Z","shell.execute_reply":"2024-04-24T17:50:59.013471Z","shell.execute_reply.started":"2024-04-24T17:50:55.960908Z"},"trusted":true},"outputs":[],"source":["def replace_low_frequency_words(sentences, threshold=UNK_CUTOFF):\n","    word_counts = Counter(word for sentence in sentences for word in sentence)\n","    replaced_sentences = [\n","        [UNKNOWN_TOKEN if word_counts[word] < threshold else word for word in sentence]\n","        for sentence in sentences\n","    ]\n","    return replaced_sentences\n","sentences=replace_low_frequency_words(sentences)\n","vocab=build_vocab_from_iterator(sentences, specials=[PAD_TOKEN])\n","vocab.set_default_index(vocab[UNKNOWN_TOKEN])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:59.016372Z","iopub.status.busy":"2024-04-24T17:50:59.015623Z","iopub.status.idle":"2024-04-24T17:50:59.072205Z","shell.execute_reply":"2024-04-24T17:50:59.071229Z","shell.execute_reply.started":"2024-04-24T17:50:59.016340Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:59.073804Z","iopub.status.busy":"2024-04-24T17:50:59.073466Z","iopub.status.idle":"2024-04-24T17:50:59.336566Z","shell.execute_reply":"2024-04-24T17:50:59.335812Z","shell.execute_reply.started":"2024-04-24T17:50:59.073779Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv('../input/ass3-curr/test.csv')\n","test_labels=df['Class Index'].tolist()\n","df=df['Description']\n","test_sentences=[]\n","for sent in df:\n","    tokenizer=RegexpTokenizer(r'\\w+')\n","    tokens=tokenizer.tokenize(sent)\n","    tokens=[token.lower() for token in tokens]\n","    test_sentences.append(tokens)\n","for sen in test_sentences:\n","    sen.insert(0,START_TOKEN)\n","    sen.append(END_TOKEN)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:59.337902Z","iopub.status.busy":"2024-04-24T17:50:59.337654Z","iopub.status.idle":"2024-04-24T17:50:59.344993Z","shell.execute_reply":"2024-04-24T17:50:59.344147Z","shell.execute_reply.started":"2024-04-24T17:50:59.337880Z"},"trusted":true},"outputs":[],"source":["class ELMO(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_size, hidden_dim, out_size):\n","        super(ELMO, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.embeddings = torch.nn.Embedding(vocab_size, embedding_size)\n","        self.lstm = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n","        self.lstm1 = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n","        self.linear = torch.nn.Linear(out_size, vocab_size)\n","    def forward(self, x):\n","        embeddings = self.embeddings(x)\n","        x1, _ = self.lstm(embeddings)\n","        x2, _ = self.lstm1(x1)\n","        x = self.linear(x2)\n","        return x, (embeddings, x1, x2)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:50:59.347103Z","iopub.status.busy":"2024-04-24T17:50:59.346278Z","iopub.status.idle":"2024-04-24T17:51:02.788905Z","shell.execute_reply":"2024-04-24T17:51:02.788067Z","shell.execute_reply.started":"2024-04-24T17:50:59.347072Z"},"trusted":true},"outputs":[],"source":["forward_model=torch.load('../input/models/forward_model.pt', map_location=torch.device('cuda'))\n","backward_model=torch.load('../input/models/backward_model.pt', map_location=torch.device('cuda'))\n","forward_model.eval()\n","backward_model.eval()\n","for param in forward_model.parameters():\n","    param.requires_grad = False\n","for param in backward_model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:51:02.790131Z","iopub.status.busy":"2024-04-24T17:51:02.789867Z","iopub.status.idle":"2024-04-24T17:51:02.801330Z","shell.execute_reply":"2024-04-24T17:51:02.800339Z","shell.execute_reply.started":"2024-04-24T17:51:02.790097Z"},"trusted":true},"outputs":[],"source":["class Dataset_LSTM(Dataset):\n","  def __init__(self, sent, labs, fm, bm,vocab):\n","    self.sentences = sent\n","    self.vocabulary=vocab\n","    self.labels = labs\n","    device='cuda'\n","    self.forward_model=fm.to(device)\n","    self.backward_model=bm.to(device)\n","  def __len__(self):\n","    return len(self.sentences)\n","  def __getitem__(self, idx):\n","    sen=[self.vocabulary[w] for w in self.sentences[idx]]\n","    return torch.tensor(sen),torch.tensor(self.labels[idx]-1)\n","  def collate(self, batch):\n","    device='cuda'\n","    sentences = [i[0] for i in batch]\n","    labels = [i[1] for i in batch]\n","    padded_sentences=pad_sequence(sentences,batch_first=True,padding_value=self.vocabulary[PAD_TOKEN]).to(device)\n","    sen_rev=torch.flip(padded_sentences,dims=[1]).to(device)\n","    _, (fe0, fe1, fe2) = self.forward_model(padded_sentences)\n","    _, (be0, be1, be2) = self.backward_model(sen_rev)\n","    be0=torch.flip(be0,dims=[1])\n","    be1=torch.flip(be1,dims=[1])\n","    be2=torch.flip(be2,dims=[1])\n","    e0=torch.cat((fe0,be0), dim=2)\n","    e1=torch.cat((fe1,be1),dim=2)\n","    e2=torch.cat((fe2,be2),dim=2)\n","    return torch.tensor(e0), torch.tensor(e1), torch.tensor(e2), torch.tensor(labels)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:51:02.805680Z","iopub.status.busy":"2024-04-24T17:51:02.805335Z","iopub.status.idle":"2024-04-24T17:51:02.977593Z","shell.execute_reply":"2024-04-24T17:51:02.976835Z","shell.execute_reply.started":"2024-04-24T17:51:02.805650Z"},"trusted":true},"outputs":[],"source":["train_dataset=Dataset_LSTM(sentences,train_labels,forward_model,backward_model,vocab)\n","test_dataset=Dataset_LSTM(test_sentences,test_labels,forward_model,backward_model,vocab)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,collate_fn=train_dataset.collate)\n","test_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,collate_fn=test_dataset.collate)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:51:02.978966Z","iopub.status.busy":"2024-04-24T17:51:02.978631Z","iopub.status.idle":"2024-04-24T17:51:02.987812Z","shell.execute_reply":"2024-04-24T17:51:02.986815Z","shell.execute_reply.started":"2024-04-24T17:51:02.978937Z"},"trusted":true},"outputs":[],"source":["class LSTMModel(torch.nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, num_classes, hyp):\n","        super(LSTMModel, self).__init__()\n","        if hyp==0:\n","            self.weight1 = torch.randn(1).to(device)\n","            self.weight2 = torch.randn(1).to(device)\n","            self.weight3 = torch.randn(1).to(device)\n","        else:\n","            self.weight1 = torch.nn.Parameter(torch.tensor(0.33))\n","            self.weight2 = torch.nn.Parameter(torch.tensor(0.33))\n","            self.weight3 = torch.nn.Parameter(torch.tensor(0.33))\n","        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, 1)\n","        self.hidden2label = torch.nn.Linear(hidden_dim, num_classes, 1)\n","    def forward(self, sentence):\n","        lstm_out, _ = self.lstm(sentence)\n","        tag_space = self.hidden2label(lstm_out[-1])\n","        tag_scores = torch.softmax(tag_space, dim=1)\n","        return tag_scores"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:51:02.989302Z","iopub.status.busy":"2024-04-24T17:51:02.989022Z","iopub.status.idle":"2024-04-24T17:51:03.001710Z","shell.execute_reply":"2024-04-24T17:51:03.000809Z","shell.execute_reply.started":"2024-04-24T17:51:02.989278Z"},"trusted":true},"outputs":[],"source":["model = LSTMModel(600, 300, NUM_LABELS, 1).to(device)\n","model=model.to(device)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=lrate)\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    model.train()\n","    for i,(e0,e1,e2,lab) in enumerate(train_dataloader):\n","        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n","        concatenated_params = torch.cat([model.weight1.unsqueeze(0),model.weight2.unsqueeze(0), model.weight3.unsqueeze(0)], dim=0)\n","        softmax_output = F.softmax(concatenated_params, dim=0)\n","        softmax_output_list = torch.split(softmax_output, 1)\n","        temp=(softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2)\n","        outputs = model(temp.permute(1,0,2))\n","        loss = loss_fn(outputs, lab)\n","        total_loss += loss.item()\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    concatenated_params = torch.cat([model.weight1,model.weight2, model.weight3], dim=0)\n","    softmax_output = F.softmax(concatenated_params, dim=0)\n","    softmax_output_list = torch.split(softmax_output, 1)\n","    print(softmax_output_list)\n","    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:51:03.003591Z","iopub.status.busy":"2024-04-24T17:51:03.003171Z","iopub.status.idle":"2024-04-24T17:51:03.090742Z","shell.execute_reply":"2024-04-24T17:51:03.089891Z","shell.execute_reply.started":"2024-04-24T17:51:03.003559Z"},"trusted":true},"outputs":[],"source":["model=torch.load('../input/classifier-model/classifier_model (1).pt')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:59:04.383609Z","iopub.status.busy":"2024-04-24T17:59:04.383253Z","iopub.status.idle":"2024-04-24T17:59:04.450563Z","shell.execute_reply":"2024-04-24T17:59:04.449600Z","shell.execute_reply.started":"2024-04-24T17:59:04.383583Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation Metrics for train set :\n","Accuracy Score: 0.9355083333333334\n","Accuracy Score: 0.9355083333333334\n","F1_Score (Macro) 0.9352673555537766\n","F1_Score (Micro) 0.9355083333333334\n","Precision Score: 0.9355610251926105\n","Recall Score: 0.9355083333333334\n","Confusion Matrix:\n"," [[27676   805   853   666]\n"," [  137 29716    59    88]\n"," [  770   335 26830  2065]\n"," [  647   277  1037 28039]]\n"]}],"source":["model.eval()\n","predictions=[]\n","true_vals=[]\n","with torch.no_grad():\n","    for e0,e1,e2,lab in train_dataloader:\n","        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n","        concatenated_params = torch.cat([model.weight1.unsqueeze(0),model.weight2.unsqueeze(0), model.weight3.unsqueeze(0)], dim=0)\n","        softmax_output = F.softmax(concatenated_params, dim=0)\n","        softmax_output_list = torch.split(softmax_output, 1)\n","        pred = model((softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2).permute(1,0,2))\n","        pred_max_index = torch.argmax(pred, dim=1)\n","        true_vals.extend(lab.cpu())\n","        predictions.extend(pred_max_index.cpu())\n","predictions=torch.stack(predictions).numpy()\n","true_vals=torch.stack(true_vals).numpy()\n","print('Evaluation Metrics for train set :')\n","print(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\n","print('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\n","print('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\n","print('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\n","print('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\n","print('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T17:59:30.717046Z","iopub.status.busy":"2024-04-24T17:59:30.716688Z","iopub.status.idle":"2024-04-24T17:59:55.757538Z","shell.execute_reply":"2024-04-24T17:59:55.756472Z","shell.execute_reply.started":"2024-04-24T17:59:30.717017Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation Metrics for test set :\n","Accuracy Score: 0.9027631578947368\n","Accuracy Score: 0.9027631578947368\n","F1_Score (Macro) 0.9022435221826568\n","F1_Score (Micro) 0.9027631578947368\n","Precision Score: 0.9025692795451862\n","Recall Score: 0.9027631578947368\n","Confusion Matrix:\n"," [[1712   60   67   61]\n"," [  16 1863   10   11]\n"," [  83   34 1592  191]\n"," [  75   27  104 1694]]\n"]}],"source":["model.eval()\n","predictions=[]\n","true_vals=[]\n","with torch.no_grad():\n","    for e0,e1,e2,lab in test_dataloader:\n","        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n","        concatenated_params = torch.cat([model.weight1.unsqueeze(0),model.weight2.unsqueeze(0), model.weight3.unsqueeze(0)], dim=0)\n","        softmax_output = F.softmax(concatenated_params, dim=0)\n","        softmax_output_list = torch.split(softmax_output, 1)\n","        pred = model((softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2).permute(1,0,2))\n","        pred_max_index = torch.argmax(pred, dim=1)\n","        true_vals.extend(lab.cpu())\n","        predictions.extend(pred_max_index.cpu())\n","predictions=torch.stack(predictions).numpy()\n","true_vals=torch.stack(true_vals).numpy()\n","print('Evaluation Metrics for test set :')\n","print(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\n","print('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\n","print('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\n","print('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\n","print('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\n","print('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:51:04.512320Z","iopub.status.idle":"2024-04-24T17:51:04.512674Z","shell.execute_reply":"2024-04-24T17:51:04.512514Z","shell.execute_reply.started":"2024-04-24T17:51:04.512500Z"},"trusted":true},"outputs":[],"source":["torch.save(model,'classifier_model.pt')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4680485,"sourceId":7957251,"sourceType":"datasetVersion"},{"datasetId":4838149,"sourceId":8174007,"sourceType":"datasetVersion"},{"datasetId":4866896,"sourceId":8212143,"sourceType":"datasetVersion"},{"datasetId":4866901,"sourceId":8212149,"sourceType":"datasetVersion"},{"datasetId":4871753,"sourceId":8218673,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
