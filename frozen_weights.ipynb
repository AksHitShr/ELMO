{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7957251,"sourceType":"datasetVersion","datasetId":4680485},{"sourceId":8174007,"sourceType":"datasetVersion","datasetId":4838149},{"sourceId":8212143,"sourceType":"datasetVersion","datasetId":4866896},{"sourceId":8212149,"sourceType":"datasetVersion","datasetId":4866901},{"sourceId":8218673,"sourceType":"datasetVersion","datasetId":4871753}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\nimport pandas as pd\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import Counter\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,confusion_matrix\nimport torch\nimport warnings\nfrom torch.utils.data import Dataset\nimport random\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:00.434994Z","iopub.execute_input":"2024-04-24T18:20:00.435345Z","iopub.status.idle":"2024-04-24T18:20:14.758503Z","shell.execute_reply.started":"2024-04-24T18:20:00.435318Z","shell.execute_reply":"2024-04-24T18:20:14.757519Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"UNK_CUTOFF=3\nUNKNOWN_TOKEN='<unk>'\nSTART_TOKEN='<sos>'\nEND_TOKEN='eos'\nPAD_TOKEN='<pad>'\n\nEMBEDDING_DIM=300\nBATCH_SIZE=128\nNUM_LABELS=4\nHIDDEN_SIZE=300\nlrate=0.001\nEPOCHS=15","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:19.747117Z","iopub.execute_input":"2024-04-24T18:20:19.747498Z","iopub.status.idle":"2024-04-24T18:20:19.753411Z","shell.execute_reply.started":"2024-04-24T18:20:19.747466Z","shell.execute_reply":"2024-04-24T18:20:19.752369Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/ass3-curr/train.csv')\ntrain_labels=df['Class Index'].tolist()\ndf=df['Description']\nwarnings.filterwarnings(\"ignore\")\nsentences=[]\nfor sent in df:\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(sent)\n    tokens=[token.lower() for token in tokens]\n    sentences.append(tokens)\nfor sen in sentences:\n    sen.insert(0,START_TOKEN)\n    sen.append(END_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:21.997030Z","iopub.execute_input":"2024-04-24T18:20:21.997414Z","iopub.status.idle":"2024-04-24T18:20:26.088310Z","shell.execute_reply.started":"2024-04-24T18:20:21.997384Z","shell.execute_reply":"2024-04-24T18:20:26.087291Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def replace_low_frequency_words(sentences, threshold=UNK_CUTOFF):\n    word_counts = Counter(word for sentence in sentences for word in sentence)\n    replaced_sentences = [\n        [UNKNOWN_TOKEN if word_counts[word] < threshold else word for word in sentence]\n        for sentence in sentences\n    ]\n    return replaced_sentences\nsentences=replace_low_frequency_words(sentences)\nvocab=build_vocab_from_iterator(sentences, specials=[PAD_TOKEN])\nvocab.set_default_index(vocab[UNKNOWN_TOKEN])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:26.089886Z","iopub.execute_input":"2024-04-24T18:20:26.090181Z","iopub.status.idle":"2024-04-24T18:20:29.720542Z","shell.execute_reply.started":"2024-04-24T18:20:26.090156Z","shell.execute_reply":"2024-04-24T18:20:29.719128Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:29.722243Z","iopub.execute_input":"2024-04-24T18:20:29.722549Z","iopub.status.idle":"2024-04-24T18:20:29.794390Z","shell.execute_reply.started":"2024-04-24T18:20:29.722522Z","shell.execute_reply":"2024-04-24T18:20:29.793209Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"df=pd.read_csv('../input/ass3-curr/test.csv')\ntest_labels=df['Class Index'].tolist()\ndf=df['Description']\ntest_sentences=[]\nfor sent in df:\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(sent)\n    tokens=[token.lower() for token in tokens]\n    test_sentences.append(tokens)\nfor sen in test_sentences:\n    sen.insert(0,START_TOKEN)\n    sen.append(END_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:32.032172Z","iopub.execute_input":"2024-04-24T18:20:32.032536Z","iopub.status.idle":"2024-04-24T18:20:32.304433Z","shell.execute_reply.started":"2024-04-24T18:20:32.032508Z","shell.execute_reply":"2024-04-24T18:20:32.303522Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ELMO(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_dim, out_size):\n        super(ELMO, self).__init__()\n        self.vocab_size = vocab_size\n        self.embeddings = torch.nn.Embedding(vocab_size, embedding_size)\n        self.lstm = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n        self.lstm1 = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n        self.linear = torch.nn.Linear(out_size, vocab_size)\n    def forward(self, x):\n        embeddings = self.embeddings(x)\n        x1, _ = self.lstm(embeddings)\n        x2, _ = self.lstm1(x1)\n        x = self.linear(x2)\n        return x, (embeddings, x1, x2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:34.464025Z","iopub.execute_input":"2024-04-24T18:20:34.464569Z","iopub.status.idle":"2024-04-24T18:20:34.473439Z","shell.execute_reply.started":"2024-04-24T18:20:34.464531Z","shell.execute_reply":"2024-04-24T18:20:34.472331Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"forward_model=torch.load('../input/models/forward_model.pt', map_location=torch.device('cuda'))\nbackward_model=torch.load('../input/models/backward_model.pt', map_location=torch.device('cuda'))\nforward_model.eval()\nbackward_model.eval()\nfor param in forward_model.parameters():\n    param.requires_grad = False\nfor param in backward_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:36.614358Z","iopub.execute_input":"2024-04-24T18:20:36.615016Z","iopub.status.idle":"2024-04-24T18:20:38.883112Z","shell.execute_reply.started":"2024-04-24T18:20:36.614984Z","shell.execute_reply":"2024-04-24T18:20:38.882125Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Dataset_LSTM(Dataset):\n  def __init__(self, sent, labs, fm, bm,vocab):\n    self.sentences = sent\n    self.vocabulary=vocab\n    self.labels = labs\n    device='cuda'\n    self.forward_model=fm.to(device)\n    self.backward_model=bm.to(device)\n  def __len__(self):\n    return len(self.sentences)\n  def __getitem__(self, idx):\n    sen=[self.vocabulary[w] for w in self.sentences[idx]]\n    return torch.tensor(sen),torch.tensor(self.labels[idx]-1)\n  def collate(self, batch):\n    device='cuda'\n    sentences = [i[0] for i in batch]\n    labels = [i[1] for i in batch]\n    padded_sentences=pad_sequence(sentences,batch_first=True,padding_value=self.vocabulary[PAD_TOKEN]).to(device)\n    sen_rev=torch.flip(padded_sentences,dims=[1]).to(device)\n    _, (fe0, fe1, fe2) = self.forward_model(padded_sentences)\n    _, (be0, be1, be2) = self.backward_model(sen_rev)\n    be0=torch.flip(be0,dims=[1])\n    be1=torch.flip(be1,dims=[1])\n    be2=torch.flip(be2,dims=[1])\n    e0=torch.cat((fe0,be0), dim=2)\n    e1=torch.cat((fe1,be1),dim=2)\n    e2=torch.cat((fe2,be2),dim=2)\n    return torch.tensor(e0), torch.tensor(e1), torch.tensor(e2), torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:38.885162Z","iopub.execute_input":"2024-04-24T18:20:38.885560Z","iopub.status.idle":"2024-04-24T18:20:38.899218Z","shell.execute_reply.started":"2024-04-24T18:20:38.885524Z","shell.execute_reply":"2024-04-24T18:20:38.898251Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset=Dataset_LSTM(sentences,train_labels,forward_model,backward_model,vocab)\ntest_dataset=Dataset_LSTM(test_sentences,test_labels,forward_model,backward_model,vocab)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,collate_fn=train_dataset.collate)\ntest_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,collate_fn=test_dataset.collate)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:42.245775Z","iopub.execute_input":"2024-04-24T18:20:42.246142Z","iopub.status.idle":"2024-04-24T18:20:42.483040Z","shell.execute_reply.started":"2024-04-24T18:20:42.246115Z","shell.execute_reply":"2024-04-24T18:20:42.481913Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(torch.nn.Module):\n    def __init__(self, embedding_dim, hidden_dim, num_classes, hyp):\n        super(LSTMModel, self).__init__()\n        if hyp==0:\n            self.weight1 = torch.randn(1).to(device)\n            self.weight2 = torch.randn(1).to(device)\n            self.weight3 = torch.randn(1).to(device)\n        else:\n            self.weight1 = torch.nn.Parameter(torch.tensor(0.33))\n            self.weight2 = torch.nn.Parameter(torch.tensor(0.33))\n            self.weight3 = torch.nn.Parameter(torch.tensor(0.33))\n        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, 1)\n        self.hidden2label = torch.nn.Linear(hidden_dim, num_classes, 1)\n    def forward(self, sentence):\n        lstm_out, _ = self.lstm(sentence)\n        tag_space = self.hidden2label(lstm_out[-1])\n        tag_scores = torch.softmax(tag_space, dim=1)\n        return tag_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:44.480569Z","iopub.execute_input":"2024-04-24T18:20:44.480961Z","iopub.status.idle":"2024-04-24T18:20:44.491147Z","shell.execute_reply.started":"2024-04-24T18:20:44.480931Z","shell.execute_reply":"2024-04-24T18:20:44.490096Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = LSTMModel(600, 300, NUM_LABELS, 0).to(device)\nmodel=model.to(device)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=lrate)\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    model.train()\n    for i,(e0,e1,e2,lab) in enumerate(train_dataloader):\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        concatenated_params = torch.cat([model.weight1,model.weight2, model.weight3], dim=0)\n        softmax_output = F.softmax(concatenated_params, dim=0)\n        softmax_output_list = torch.split(softmax_output, 1)\n        temp=(softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2)\n        outputs = model(temp.permute(1,0,2))\n        loss = loss_fn(outputs, lab)\n        total_loss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    concatenated_params = torch.cat([model.weight1,model.weight2, model.weight3], dim=0)\n    softmax_output = F.softmax(concatenated_params, dim=0)\n    softmax_output_list = torch.split(softmax_output, 1)\n    print(softmax_output_list)\n    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T18:20:46.883053Z","iopub.execute_input":"2024-04-24T18:20:46.883459Z","iopub.status.idle":"2024-04-24T19:49:35.993567Z","shell.execute_reply.started":"2024-04-24T18:20:46.883429Z","shell.execute_reply":"2024-04-24T19:49:35.992529Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 1, Loss: 1047.9226353168488\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 2, Loss: 813.4645037651062\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 3, Loss: 804.263430595398\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 4, Loss: 799.0067749023438\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 5, Loss: 793.0101532936096\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 6, Loss: 786.8861422538757\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 7, Loss: 782.1426312327385\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 8, Loss: 778.131151497364\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 9, Loss: 774.4742756485939\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 10, Loss: 771.2626666426659\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 11, Loss: 767.627797305584\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 12, Loss: 763.9644622802734\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 13, Loss: 763.2722398638725\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 14, Loss: 760.4627735614777\n(tensor([0.1741], device='cuda:0'), tensor([0.2934], device='cuda:0'), tensor([0.5324], device='cuda:0'))\nEpoch 15, Loss: 757.9263670444489\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions=[]\ntrue_vals=[]\nwith torch.no_grad():\n    for e0,e1,e2,lab in train_dataloader:\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        concatenated_params = torch.cat([model.weight1,model.weight2, model.weight3], dim=0)\n        softmax_output = F.softmax(concatenated_params, dim=0)\n        softmax_output_list = torch.split(softmax_output, 1)\n        pred = model((softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2).permute(1,0,2))\n        pred_max_index = torch.argmax(pred, dim=1)\n        true_vals.extend(lab.cpu())\n        predictions.extend(pred_max_index.cpu())\npredictions=torch.stack(predictions).numpy()\ntrue_vals=torch.stack(true_vals).numpy()\nprint('Evaluation Metrics for train set :')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\nprint('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\nprint('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\nprint('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\nprint('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:49:35.995375Z","iopub.execute_input":"2024-04-24T19:49:35.995881Z","iopub.status.idle":"2024-04-24T19:55:18.155097Z","shell.execute_reply.started":"2024-04-24T19:49:35.995853Z","shell.execute_reply":"2024-04-24T19:55:18.154126Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Evaluation Metrics for train set :\nAccuracy Score: 0.9293083333333333\nAccuracy Score: 0.9293083333333333\nF1_Score (Macro) 0.929334680245494\nF1_Score (Micro) 0.9293083333333332\nPrecision Score: 0.93005162367612\nRecall Score: 0.9293083333333333\nConfusion Matrix:\n [[27568   705  1112   615]\n [  208 29491   209    92]\n [  584   130 27808  1478]\n [  639   114  2597 26650]]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions=[]\ntrue_vals=[]\nwith torch.no_grad():\n    for e0,e1,e2,lab in test_dataloader:\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        concatenated_params = torch.cat([model.weight1,model.weight2, model.weight3], dim=0)\n        softmax_output = F.softmax(concatenated_params, dim=0)\n        softmax_output_list = torch.split(softmax_output, 1)\n        pred = model((softmax_output_list[0]*e0+softmax_output_list[1]*e1+softmax_output_list[2]*e2).permute(1,0,2))\n        pred_max_index = torch.argmax(pred, dim=1)\n        true_vals.extend(lab.cpu())\n        predictions.extend(pred_max_index.cpu())\npredictions=torch.stack(predictions).numpy()\ntrue_vals=torch.stack(true_vals).numpy()\nprint('Evaluation Metrics for test set :')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\nprint('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\nprint('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\nprint('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\nprint('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:55:18.156473Z","iopub.execute_input":"2024-04-24T19:55:18.156742Z","iopub.status.idle":"2024-04-24T19:55:40.281053Z","shell.execute_reply.started":"2024-04-24T19:55:18.156719Z","shell.execute_reply":"2024-04-24T19:55:40.280110Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Evaluation Metrics for test set :\nAccuracy Score: 0.9040789473684211\nAccuracy Score: 0.9040789473684211\nF1_Score (Macro) 0.9041496178362354\nF1_Score (Micro) 0.9040789473684211\nPrecision Score: 0.9051782221813239\nRecall Score: 0.9040789473684211\nConfusion Matrix:\n [[1705   48   94   53]\n [  26 1841   23   10]\n [  58   10 1713  119]\n [  70    9  209 1612]]\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model,'classifier_model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}