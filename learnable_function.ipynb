{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7957251,"sourceType":"datasetVersion","datasetId":4680485},{"sourceId":8174007,"sourceType":"datasetVersion","datasetId":4838149},{"sourceId":8212143,"sourceType":"datasetVersion","datasetId":4866896},{"sourceId":8212149,"sourceType":"datasetVersion","datasetId":4866901}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\nimport pandas as pd\nfrom torch.nn.utils.rnn import pad_sequence\nfrom collections import Counter\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,confusion_matrix\nimport torch\nimport warnings\nfrom torch.utils.data import Dataset\nimport random\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:10.502865Z","iopub.execute_input":"2024-04-24T20:13:10.503255Z","iopub.status.idle":"2024-04-24T20:13:17.756920Z","shell.execute_reply.started":"2024-04-24T20:13:10.503225Z","shell.execute_reply":"2024-04-24T20:13:17.756094Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"UNK_CUTOFF=3\nUNKNOWN_TOKEN='<unk>'\nSTART_TOKEN='<sos>'\nEND_TOKEN='eos'\nPAD_TOKEN='<pad>'\n\nEMBEDDING_DIM=300\nBATCH_SIZE=128\nNUM_LABELS=4\nHIDDEN_SIZE=300\nlrate=0.0001\nEPOCHS=15","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:17.758830Z","iopub.execute_input":"2024-04-24T20:13:17.759568Z","iopub.status.idle":"2024-04-24T20:13:17.765025Z","shell.execute_reply.started":"2024-04-24T20:13:17.759533Z","shell.execute_reply":"2024-04-24T20:13:17.764039Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/ass3-curr/train.csv')\ntrain_labels=df['Class Index'].tolist()\ndf=df['Description']\nwarnings.filterwarnings(\"ignore\")\nsentences=[]\nfor sent in df:\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(sent)\n    tokens=[token.lower() for token in tokens]\n    sentences.append(tokens)\nfor sen in sentences:\n    sen.insert(0,START_TOKEN)\n    sen.append(END_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:17.766268Z","iopub.execute_input":"2024-04-24T20:13:17.766995Z","iopub.status.idle":"2024-04-24T20:13:21.332893Z","shell.execute_reply.started":"2024-04-24T20:13:17.766963Z","shell.execute_reply":"2024-04-24T20:13:21.331926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def replace_low_frequency_words(sentences, threshold=UNK_CUTOFF):\n    word_counts = Counter(word for sentence in sentences for word in sentence)\n    replaced_sentences = [\n        [UNKNOWN_TOKEN if word_counts[word] < threshold else word for word in sentence]\n        for sentence in sentences\n    ]\n    return replaced_sentences\nsentences=replace_low_frequency_words(sentences)\nvocab=build_vocab_from_iterator(sentences, specials=[PAD_TOKEN])\nvocab.set_default_index(vocab[UNKNOWN_TOKEN])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:21.334933Z","iopub.execute_input":"2024-04-24T20:13:21.335278Z","iopub.status.idle":"2024-04-24T20:13:24.323033Z","shell.execute_reply.started":"2024-04-24T20:13:21.335252Z","shell.execute_reply":"2024-04-24T20:13:24.322050Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:24.324170Z","iopub.execute_input":"2024-04-24T20:13:24.324432Z","iopub.status.idle":"2024-04-24T20:13:24.351781Z","shell.execute_reply.started":"2024-04-24T20:13:24.324410Z","shell.execute_reply":"2024-04-24T20:13:24.350899Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"df=pd.read_csv('../input/ass3-curr/test.csv')\ntest_labels=df['Class Index'].tolist()\ndf=df['Description']\ntest_sentences=[]\nfor sent in df:\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(sent)\n    tokens=[token.lower() for token in tokens]\n    test_sentences.append(tokens)\nfor sen in test_sentences:\n    sen.insert(0,START_TOKEN)\n    sen.append(END_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:24.352850Z","iopub.execute_input":"2024-04-24T20:13:24.353104Z","iopub.status.idle":"2024-04-24T20:13:24.586432Z","shell.execute_reply.started":"2024-04-24T20:13:24.353082Z","shell.execute_reply":"2024-04-24T20:13:24.585404Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ELMO(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_dim, out_size):\n        super(ELMO, self).__init__()\n        self.vocab_size = vocab_size\n        self.embeddings = torch.nn.Embedding(vocab_size, embedding_size)\n        self.lstm = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n        self.lstm1 = torch.nn.LSTM(hidden_dim, out_size, 1, batch_first=True)\n        self.linear = torch.nn.Linear(out_size, vocab_size)\n    def forward(self, x):\n        embeddings = self.embeddings(x)\n        x1, _ = self.lstm(embeddings)\n        x2, _ = self.lstm1(x1)\n        x = self.linear(x2)\n        return x, (embeddings, x1, x2)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:24.587627Z","iopub.execute_input":"2024-04-24T20:13:24.587917Z","iopub.status.idle":"2024-04-24T20:13:24.595370Z","shell.execute_reply.started":"2024-04-24T20:13:24.587892Z","shell.execute_reply":"2024-04-24T20:13:24.594366Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"forward_model=torch.load('../input/models/forward_model.pt', map_location=torch.device('cuda'))\nbackward_model=torch.load('../input/models/backward_model.pt', map_location=torch.device('cuda'))\nforward_model.eval()\nbackward_model.eval()\nfor param in forward_model.parameters():\n    param.requires_grad = False\nfor param in backward_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:24.596588Z","iopub.execute_input":"2024-04-24T20:13:24.596874Z","iopub.status.idle":"2024-04-24T20:13:26.666942Z","shell.execute_reply.started":"2024-04-24T20:13:24.596851Z","shell.execute_reply":"2024-04-24T20:13:26.666163Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Dataset_LSTM(Dataset):\n  def __init__(self, sent, labs, fm, bm,vocab):\n    self.sentences = sent\n    self.vocabulary=vocab\n    self.labels = labs\n    device='cuda'\n    self.forward_model=fm.to(device)\n    self.backward_model=bm.to(device)\n  def __len__(self):\n    return len(self.sentences)\n  def __getitem__(self, idx):\n    sen=[self.vocabulary[w] for w in self.sentences[idx]]\n    return torch.tensor(sen),torch.tensor(self.labels[idx]-1)\n  def collate(self, batch):\n    device='cuda'\n    sentences = [i[0] for i in batch]\n    labels = [i[1] for i in batch]\n    padded_sentences=pad_sequence(sentences,batch_first=True,padding_value=self.vocabulary[PAD_TOKEN]).to(device)\n    sen_rev=torch.flip(padded_sentences,dims=[1]).to(device)\n    _, (fe0, fe1, fe2) = self.forward_model(padded_sentences)\n    _, (be0, be1, be2) = self.backward_model(sen_rev)\n    be0=torch.flip(be0,dims=[1])\n    be1=torch.flip(be1,dims=[1])\n    be2=torch.flip(be2,dims=[1])\n    e0=torch.cat((fe0,be0), dim=2)\n    e1=torch.cat((fe1,be1),dim=2)\n    e2=torch.cat((fe2,be2),dim=2)\n    return torch.tensor(e0), torch.tensor(e1), torch.tensor(e2), torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:26.667998Z","iopub.execute_input":"2024-04-24T20:13:26.668269Z","iopub.status.idle":"2024-04-24T20:13:26.679444Z","shell.execute_reply.started":"2024-04-24T20:13:26.668247Z","shell.execute_reply":"2024-04-24T20:13:26.678330Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset=Dataset_LSTM(sentences,train_labels,forward_model,backward_model,vocab)\ntest_dataset=Dataset_LSTM(test_sentences,test_labels,forward_model,backward_model,vocab)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,collate_fn=train_dataset.collate)\ntest_dataloader=DataLoader(test_dataset,batch_size=BATCH_SIZE,collate_fn=test_dataset.collate)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:26.682242Z","iopub.execute_input":"2024-04-24T20:13:26.682505Z","iopub.status.idle":"2024-04-24T20:13:26.808446Z","shell.execute_reply.started":"2024-04-24T20:13:26.682483Z","shell.execute_reply":"2024-04-24T20:13:26.807649Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(torch.nn.Module):\n    def __init__(self, embedding_dim, hidden_dim, num_classes):\n        super(LSTMModel, self).__init__()\n        self.linear_layer=torch.nn.Linear(3*embedding_dim,embedding_dim)\n        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, 1)\n        self.hidden2label = torch.nn.Linear(hidden_dim, num_classes, 1)\n    def forward(self, sentence):\n        lin_out=self.linear_layer(sentence)\n        lstm_out, _ = self.lstm(lin_out.permute(1,0,2))\n        tag_space = self.hidden2label(lstm_out[-1])\n        tag_scores = torch.softmax(tag_space, dim=1)\n        return tag_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:26.809540Z","iopub.execute_input":"2024-04-24T20:13:26.809885Z","iopub.status.idle":"2024-04-24T20:13:26.816977Z","shell.execute_reply.started":"2024-04-24T20:13:26.809854Z","shell.execute_reply":"2024-04-24T20:13:26.816103Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = LSTMModel(600, 300, NUM_LABELS).to(device)\nmodel=model.to(device)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=lrate)\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    model.train()\n    for i,(e0,e1,e2,lab) in enumerate(train_dataloader):\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        temp=torch.cat((e0, e1, e2), dim=2)\n        outputs = model(temp)\n        loss = loss_fn(outputs, lab)\n        total_loss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:13:26.818272Z","iopub.execute_input":"2024-04-24T20:13:26.818816Z","iopub.status.idle":"2024-04-24T20:46:59.675496Z","shell.execute_reply.started":"2024-04-24T20:13:26.818784Z","shell.execute_reply":"2024-04-24T20:46:59.674549Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1128.034928381443\nEpoch 2, Loss: 803.3057749867439\nEpoch 3, Loss: 793.1715704202652\nEpoch 4, Loss: 785.9826110005379\nEpoch 5, Loss: 781.4371819496155\nEpoch 6, Loss: 776.9395772814751\nEpoch 7, Loss: 773.5107178092003\nEpoch 8, Loss: 770.1154091954231\nEpoch 9, Loss: 766.880840420723\nEpoch 10, Loss: 764.5043134689331\nEpoch 11, Loss: 762.3880754113197\nEpoch 12, Loss: 760.6643586754799\nEpoch 13, Loss: 757.7806669473648\nEpoch 14, Loss: 756.1469175219536\nEpoch 15, Loss: 755.0172337293625\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions=[]\ntrue_vals=[]\nwith torch.no_grad():\n    for e0,e1,e2,lab in train_dataloader:\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        temp=torch.cat((e0, e1, e2), dim=2)\n        pred = model(temp)\n        pred_max_index = torch.argmax(pred, dim=1)\n        true_vals.extend(lab.cpu())\n        predictions.extend(pred_max_index.cpu())\npredictions=torch.stack(predictions).numpy()\ntrue_vals=torch.stack(true_vals).numpy()\nprint('Evaluation Metrics for train set :')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\nprint('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\nprint('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\nprint('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\nprint('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:46:59.676554Z","iopub.execute_input":"2024-04-24T20:46:59.677009Z","iopub.status.idle":"2024-04-24T20:49:08.494629Z","shell.execute_reply.started":"2024-04-24T20:46:59.676986Z","shell.execute_reply":"2024-04-24T20:49:08.493663Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Evaluation Metrics for train set :\nAccuracy Score: 0.9321166666666667\nF1_Score (Macro) 0.9320165007050719\nF1_Score (Micro) 0.9321166666666667\nPrecision Score: 0.9322300718370463\nRecall Score: 0.9321166666666667\nConfusion Matrix:\n [[27721   768   907   604]\n [  231 29553   142    74]\n [  617   150 27709  1524]\n [  831   115  2183 26871]]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions=[]\ntrue_vals=[]\nwith torch.no_grad():\n    for e0,e1,e2,lab in test_dataloader:\n        (e0,e1,e2,lab) = (e0.to(device), e1.to(device), e2.to(device), lab.to(device))\n        temp=torch.cat((e0, e1, e2), dim=2)\n        pred = model(temp)\n        pred_max_index = torch.argmax(pred, dim=1)\n        true_vals.extend(lab.cpu())\n        predictions.extend(pred_max_index.cpu())\npredictions=torch.stack(predictions).numpy()\ntrue_vals=torch.stack(true_vals).numpy()\nprint('Evaluation Metrics for test set :')\nprint(f'Accuracy Score: {accuracy_score(true_vals,predictions)}')\nprint('F1_Score (Macro)',f1_score(true_vals,predictions, average='macro'))\nprint('F1_Score (Micro)', f1_score(true_vals,predictions, average='micro'))\nprint('Precision Score:', precision_score(true_vals,predictions, average='weighted'))\nprint('Recall Score:',recall_score(true_vals,predictions, average='weighted'))\nprint('Confusion Matrix:\\n',confusion_matrix(true_vals,predictions))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:49:08.495966Z","iopub.execute_input":"2024-04-24T20:49:08.496637Z","iopub.status.idle":"2024-04-24T20:49:16.773081Z","shell.execute_reply.started":"2024-04-24T20:49:08.496593Z","shell.execute_reply":"2024-04-24T20:49:16.771976Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Evaluation Metrics for test set :\nAccuracy Score: 0.9022368421052631\nF1_Score (Macro) 0.9021042458486019\nF1_Score (Micro) 0.9022368421052631\nPrecision Score: 0.9026377280303072\nRecall Score: 0.9022368421052631\nConfusion Matrix:\n [[1715   53   82   50]\n [  30 1842   18   10]\n [  61   12 1698  129]\n [  85   14  199 1602]]\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model,'classifier_model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:49:16.774143Z","iopub.execute_input":"2024-04-24T20:49:16.774421Z","iopub.status.idle":"2024-04-24T20:49:16.793527Z","shell.execute_reply.started":"2024-04-24T20:49:16.774397Z","shell.execute_reply":"2024-04-24T20:49:16.792488Z"},"trusted":true},"execution_count":15,"outputs":[]}]}